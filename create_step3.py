# ===============================================
# Gankhuyag Whisper Dataset: Full Generator (‚âà20k)
# Mongolian (bank + daily + tech + numbers/currency)
# ===============================================
import os, csv, random, math, itertools, hashlib
from collections import defaultdict
from datetime import datetime
from tqdm import tqdm

# ------------ CONFIG ------------
# Change this if running locally (e.g., "Gankhuyag_Whisper_Data")
BASE_DIR = "Whisper_Data"
TARGET_SENTENCES = 20000         # ‚âà 20k meaningful sentences
TARGET_EXPRESSIONS = 8000        # 2‚Äì3 word expressions
SEED = 42                        # reproducibility

random.seed(SEED)
os.makedirs(BASE_DIR, exist_ok=True)

# ------------ CORE LEXICON (seed sets) ------------
# Bank & finance nouns
BANK = [
  "–¥–∞–Ω—Å","–≥“Ø–π–ª–≥—ç—ç","–º”©–Ω–≥”©","—Ç”©–ª–±”©—Ä","–∞—Ä–∏–ª–∂–∞–∞","—Ö—É–¥–∞–ª–¥–∞–∞","–≤–∞–ª—é—Ç","—Ö–∞–Ω—à","–∞—à–∏–≥","–∞–ª–¥–∞–≥–¥–∞–ª",
  "–æ—Ä–ª–æ–≥–æ","–∑–∞—Ä–ª–∞–≥–∞","–±–∞–ª–∞–Ω—Å","–∑—ç—ç–ª","–∫–∞—Ä—Ç","—Ö–∞–¥–≥–∞–ª–∞–º–∂","–∞–≤–ª–∞–≥–∞","”©—Ä","–Ω–æ—Ç–ª–æ—Ö –±–∞—Ä–∏–º—Ç",
  "–±–∞—Ä–∏–º—Ç","–∫–≤–∏—Ç–∞–Ω—Ü","—Ç–µ—Ä–º–∏–Ω–∞–ª","ATM","POS —Ç”©—Ö”©”©—Ä”©–º–∂","–∫–∞—Ä—Ç —É–Ω—à–∏–≥—á","—Å–∞–ª–±–∞—Ä","–±–∞–Ω–∫",
  "–¥–∞–Ω—Å–Ω—ã –¥—É–≥–∞–∞—Ä","–¥–∞–Ω—Å–Ω—ã –Ω—ç—Ä","–∏–Ω—Ç–µ—Ä–Ω—ç—Ç –±–∞–Ω–∫","—Ü–∞—Ö–∏–º –±–∞–Ω–∫","—à–∏–ª–∂“Ø“Ø–ª—ç–≥"
]

# Tech & digital
TECH = [
  "–±–∞—Ä –∫–æ–¥","QR –∫–æ–¥","—Å–∫–∞–Ω —Ö–∏–π—Ö","—Å–∫–∞–Ω–Ω–µ—Ä","—Ö—É—É–ª–±–∞—Ä–ª–∞—Ö","–∫–æ–ø–∏ —Ö–∏–π—Ö","–ø—Ä–∏–Ω—Ç–µ—Ä","–≤–µ–± —Ö—É—É–¥–∞—Å",
  "–≤–µ–± —Å–∞–π—Ç","–∞–ø–ø","–ø—Ä–æ–≥—Ä–∞–º","—Ü–∞—Ö–∏–º –±–∞—Ä–∏–º—Ç","—Ü–∞—Ö–∏–º “Ø–π–ª—á–∏–ª–≥—ç—ç","–Ω—É—É—Ü “Ø–≥","–ø–∏–Ω –∫–æ–¥",
  "–±–∞—Ç–∞–ª–≥–∞–∞–∂—É—É–ª–∞—Ö –∫–æ–¥","OTP –∫–æ–¥","–∏–º—ç–π–ª","—Ü–∞—Ö–∏–º —à—É—É–¥–∞–Ω","wifi","bluetooth","notification",
  "update","install","download","upload","–Ω—ç–≤—Ç—Ä—ç—Ö","–≥–∞—Ä–∞—Ö","—Ö–∞–Ω–¥–∞–ª—Ç","—Ñ–∞–π–ª","—Ñ–∞–π–ª —Ö—É—É–ª–±–∞—Ä",
  "—Ñ–∞–π–ª –∏–ª–≥—ç—ç—Ö","—Ñ–∞–π–ª —É—Å—Ç–≥–∞—Ö","–∑—É—Ä–∞–≥","–≤–∏–¥–µ–æ","–∫–æ–¥","–∞–ª–≥–æ—Ä–∏—Ç–º","–º—ç–¥—ç—ç–ª–ª–∏–π–Ω —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏",
  "”©–≥”©–≥–¥”©–ª","”©–≥”©–≥–¥–ª–∏–π–Ω —Å–∞–Ω","—Ö–∏–π–º—ç–ª –æ—é—É–Ω","—Ö–∏–π–º—ç–ª –æ—é—É–Ω —É—Ö–∞–∞–Ω","AI","IA","–º–∞—à–∏–Ω —Å—É—Ä–≥–∞–ª—Ç",
  "–Ω–µ–π—Ä–æ–Ω —Å“Ø–ª–∂—ç—ç","—Ä–æ–±–æ—Ç","—Ä–æ–±–æ—Ç —Å–∏—Å—Ç–µ–º"
]

# Daily life nouns
DAILY = [
  "–¥—ç–ª–≥“Ø“Ø—Ä","—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç","–∑–∞—Ö","—Ä–µ—Å—Ç–æ—Ä–∞–Ω","–∫–∞—Ñ–µ","–≥—ç—Ä","–æ—Ä–æ–Ω —Å—É—É—Ü","–±–∞–π—à–∏–Ω","”©—Ä”©”©","–≥—É–¥–∞–º–∂","—Ç–∞–ª–±–∞–π",
  "–º–∞—à–∏–Ω","–∞–≤—Ç–æ–±—É—Å","–≥–∞–ª—Ç —Ç—ç—Ä—ç–≥","–æ–Ω–≥–æ—Ü","—à–∞—Ç–∞—Ö—É—É–Ω","–∑–æ–≥—Å–æ–æ–ª","—ç–º–Ω—ç–ª—ç–≥","—ç–º—á","—ç–º","”©–≤—á–∏–Ω","—ç–º—á–∏–ª–≥—ç—ç",
  "–∫–æ—Ñ–µ","—Ü–∞–π","—É—Å","—à–∞—Ä –∞–π—Ä–∞–≥","—Ç–∞–ª—Ö","–≥—É—Ä–∏–ª","–±—É–¥–∞–∞","–º–∞—Ö","–Ω–æ–≥–æ–æ","—á–∏—Ö—ç—Ä","–∞–º—Ç—Ç–∞–Ω","—Å“Ø“Ø","”©–Ω–¥”©–≥","—Å–∞–ª–∞—Ç",
  "–º—É—É—Ä","–Ω–æ—Ö–æ–π","—à—É–≤—É—É","–∑–∞–≥–∞—Å","—Ö“Ø“Ø—Ö—ç–¥","–±–∞–≥—à","–æ—é—É—Ç–∞–Ω","–∞–∂–∏–ª—Ç–∞–Ω","–º–µ–Ω–µ–∂–µ—Ä","—É–¥–∏—Ä–¥–ª–∞–≥–∞","–Ω–∞–π–∑","–∞—Ö","—ç–≥—á"
]

# Weather & nature
NATURE = [
  "—Ü–∞–≥ –∞–≥–∞–∞—Ä","–Ω–∞—Ä","–±–æ—Ä–æ–æ","—Ü–∞—Å","—Å–∞–ª—Ö–∏","—Å–∞–ª—Ö–∏—Ç–∞–π","–±–æ—Ä–æ–æ—Ç–æ–π","–±“Ø“Ø–¥–≥—ç—Ä","—Ü—ç–ª–º—ç–≥","–¥—É–ª–∞–∞–Ω","—Ö“Ø–π—Ç—ç–Ω","—Ö–∞–ª—É—É–Ω","—Å—ç—Ä“Ø“Ø–Ω",
  "—É—É–ª","–≥–æ–ª","–Ω—É—É—Ä","–º–æ–¥","—Ü—ç—Ü—ç–≥","–Ω–∞–≤—á","—à–æ—Ä–æ–æ","–∑–∞–º"
]

# Time words
TIME = [
  "”©–Ω”©”©–¥”©—Ä","–º–∞—Ä–≥–∞–∞—à","”©—á–∏–≥–¥”©—Ä","”©–≥–ª”©”©","”©–¥”©—Ä","–æ—Ä–æ–π","—à”©–Ω”©","7 —Ü–∞–≥—Ç","8 —Ü–∞–≥—Ç","”©–Ω–≥”©—Ä—Å”©–Ω –¥–æ–ª–æ–æ —Ö–æ–Ω–æ–≥—Ç","–¥–∞—Ä–∞–∞ —Å–∞—Ä—ã–Ω —ç—Ö—ç–Ω–¥"
]

# People / roles
PEOPLE = [
  "–±–∏","—á–∏","—Ç—ç—Ä","–∞—Ö","—ç–≥—á","–∞–∞–≤","—ç—ç–∂","–Ω–∞–π–∑","“Ø–π–ª—á–ª“Ø“Ø–ª—ç–≥—á","—Ö—ç—Ä—ç–≥–ª—ç–≥—á","—Ö–∞–º—Ç –æ–ª–æ–Ω","–º–µ–Ω–µ–∂–µ—Ä","–∫–∞—Å—Ç–æ–º–µ—Ä","—Ö“Ø“Ø—Ö—ç–¥"
]

# Verbs (bank + general)
VERBS = [
  "—à–∞–ª–≥–∞—Ö","—Ç”©–ª”©—Ö","–∞–≤–∞—Ö","”©–≥”©—Ö","–Ω—ç—ç—Ö","—Ö–∞–∞—Ö","—à–∏–ª–∂“Ø“Ø–ª—ç—Ö","–±–∞—Ç–∞–ª–≥–∞–∞–∂—É—É–ª–∞—Ö","–∏–ª–≥—ç—ç—Ö","—Ö“Ø–ª—ç—ç–Ω –∞–≤–∞—Ö",
  "–∞—Å—É—É—Ö","—Ö–∞—Ä–∏—É–ª–∞—Ö","—Ç–∞—Ç–∞—Ö","–æ—Ä—É—É–ª–∂ ”©–≥”©—Ö","—Å–æ–Ω–≥–æ—Ö","–∑–∞—Å–∞—Ö","—É—Å—Ç–≥–∞—Ö","—Ö–∞–π—Ö","–¥–∞–Ω—Å–∞–∞ —à–∞–ª–≥–∞—Ö",
  "–≥“Ø–π–ª–≥—ç—ç —Ö–∏–π—Ö","–≤–∞–ª—é—Ç —Å–æ–ª–∏—Ö","–∑—ç—ç–ª –∞–≤–∞—Ö","–∫–∞—Ä—Ç –∞—à–∏–≥–ª–∞—Ö","–∫–æ–¥ –±–∏—á–∏—Ö","—Ñ–∞–π–ª –∏–ª–≥—ç—ç—Ö","—Å–∫–∞–Ω —Ö–∏–π—Ö",
  "—Ö—É—É–ª–±–∞—Ä–ª–∞—Ö","—Ö—ç–≤–ª—ç—Ö","–∞—Ä–∏–ª–∂–∞–∞ —Ö–∏–π—Ö","—Ö—É–¥–∞–ª–¥–∞–∂ –∞–≤–∞—Ö","—Ö—É–¥–∞–ª–¥–∞—Ö","—Å—É–¥–ª–∞—Ö","–±–∏—á–∏—Ö","—É–Ω—à–∏—Ö","—É—É—Ö","–∏–¥—ç—Ö",
  "–±–æ–¥–æ–ª—Ö–∏–π–ª—ç—Ö","—Ç—É—Ä—à–∏—Ö","–∑”©–≤–ª”©—Ö","—Ç–æ–≥–ª–æ—Ö","–∞—è–ª–∞—Ö","–∞–º—Ä–∞—Ö","—è—Ä–∏–ª—Ü–∞—Ö","–∑–∞–ª–≥–∞—Ö","–æ—á–∏—Ö","—è–≤–∞—Ö","–∏—Ä—ç—Ö"
]

EMOTION = ["–±–∞—è—Ä—Ç–∞–π","–≥—É–Ω–∏–≥—Ç–∞–π","—É—É—Ä—Ç–∞–π","—Å–∞–Ω–∞–∞ –∑–æ–≤—Å–æ–Ω","–∏—Ç–≥—ç–ª—Ç—ç–π","–Ω–∞–π–¥–≤–∞—Ä—Ç–∞–π","—Ç–∞–π–≤–∞–Ω","—è–∞—Ä–∞–ª—Ç–∞–π"]

# Currency units
CURRENCIES = ["—Ç”©–≥—Ä”©–≥","–¥–æ–ª–ª–∞—Ä","–µ–≤—Ä–æ","—é–∞–Ω—å","—Ä—É–±–ª—å"]

# ------------ Numbers ‚Üí Mongolian words (basic) ------------
ONES = ["–Ω—ç–≥","—Ö–æ—ë—Ä","–≥—É—Ä–≤–∞–Ω","–¥”©—Ä–≤”©–Ω","—Ç–∞–≤–∞–Ω","–∑—É—Ä–≥–∞–∞–Ω","–¥–æ–ª–æ–æ–Ω","–Ω–∞–π–º–∞–Ω","–µ—Å”©–Ω"]
ONES_PLAIN = ["–Ω—ç–≥","—Ö–æ—ë—Ä","–≥—É—Ä–∞–≤","–¥”©—Ä”©–≤","—Ç–∞–≤","–∑—É—Ä–≥–∞–∞","–¥–æ–ª–æ–æ","–Ω–∞–π–º","–µ—Å"]
TENS = ["–∞—Ä–∞–≤","—Ö–æ—Ä–∏–Ω","–≥—É—á–∏–Ω","–¥”©—á–∏–Ω","—Ç–∞–≤–∏–Ω","–∂–∞—Ä","–¥–∞–ª","–Ω–∞—è","–µ—Ä"]
HUNDRED = "–∑—É—É"
THOUSAND = "–º—è–Ω–≥–∞"
THOUSAND_MOD = "–º—è–Ω–≥–∞–Ω"
MILLION = "—Å–∞—è"
BILLION = "—Ç—ç—Ä–±—É–º"

def two_digit(n):
    if n < 10: return ONES_PLAIN[n-1]
    if n == 10: return "–∞—Ä–∞–≤"
    if 11 <= n <= 19:
        return "–∞—Ä–≤–∞–Ω " + ONES_PLAIN[n-10-1]
    t = n // 10; u = n % 10
    base = TENS[t-1]
    if u == 0: return base
    return base + " " + ONES_PLAIN[u-1]

def three_digit(n):
    if n < 100: return two_digit(n)
    h = n // 100; rest = n % 100
    hword = (ONES[h-1] + " " + HUNDRED)
    if rest == 0: return hword
    return hword + " " + two_digit(rest)

def number_words(n):
    if n < 1000: return three_digit(n)
    if n < 1000000:
        k = n // 1000; rest = n % 1000
        kth = number_words(k) + " " + THOUSAND
        if rest == 0: return kth
        return kth + " " + three_digit(rest)
    if n < 1000000000:
        m = n // 1000000; rest = n % 1000000
        mth = number_words(m) + " " + MILLION
        if rest == 0: return mth
        # ensure spacing
        part = (number_words(rest))
        return mth + " " + part
    b = n // 1000000000; rest = n % 1000000000
    bth = number_words(b) + " " + BILLION
    if rest == 0: return bth
    return bth + " " + number_words(rest)

def thousand_modified(n):
    # e.g., "–Ω—ç–≥ –º—è–Ω–≥–∞–Ω —Ç”©–≥—Ä”©–≥" (modifier form)
    if n == 1: return "–Ω—ç–≥ " + THOUSAND_MOD
    # for 2..9, use ONES + –º—è–Ω–≥–∞–Ω
    if 2 <= n <= 9: return ONES[n-1] + " " + THOUSAND_MOD
    # default fallback
    return number_words(n) + " " + THOUSAND

# ------------ Build word_list (‚âà2000+) ------------
BASE_WORDS = sorted(set(BANK + TECH + DAILY + NATURE + TIME + PEOPLE + VERBS + EMOTION))
word_list = list(BASE_WORDS)

# Add numeric/currency tokens
for n in [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,200,300,500,700,900]:
    for cur in CURRENCIES:
        word_list.append(f"{number_words(n)} {cur}")
for n in range(1,10):
    word_list.append(thousand_modified(n))  # "–Ω—ç–≥ –º—è–Ω–≥–∞–Ω", "—Ö–æ—ë—Ä –º—è–Ω–≥–∞–Ω", ...

# Add extra tech/AI slang variants
word_list += ["QR –≥“Ø–π–ª–≥—ç—ç","–±–∞—Ä –∫–æ–¥ —É–Ω—à—É—É–ª–∞—Ö","—Ü–∞—Ö–∏–º –Ω—ç–≤—Ç—Ä—ç–ª—Ç","–¥–∞–Ω—Å–Ω—ã “Ø–ª–¥—ç–≥–¥—ç–ª","—Ö–∞—Ä–∞–≥–¥–∞—Ö –±–∞–π–¥–∞–ª","—Ñ–æ—Ä–º","—Ç–∞–ª–±–∞—Ä"]

# Dedup + sort
word_list = sorted(set(w.strip() for w in word_list if w.strip()))

# Write word_list.txt
with open(os.path.join(BASE_DIR,"word_list.txt"),"w",encoding="utf-8") as f:
    f.write("\n".join(word_list))

# ------------ Build expressions (2‚Äì3 word phrases) ------------
def pairs(a, b, verb_last=True):
    out = []
    for x in a:
        for y in b:
            if verb_last: out.append(f"{x} {y}")
            else: out.append(f"{y} {x}")
    return out

EXP_BANK = []
EXP_BANK += [f"{n} {v}" for n in ["–¥–∞–Ω—Å","–≥“Ø–π–ª–≥—ç—ç","—Ç”©–ª–±”©—Ä","–≤–∞–ª—é—Ç","–∑—ç—ç–ª","–∫–∞—Ä—Ç"] for v in ["—à–∞–ª–≥–∞—Ö","—Ç”©–ª”©—Ö","–∞–≤–∞—Ö","–Ω—ç—ç—Ö","—Ö–∞–∞—Ö","—à–∏–ª–∂“Ø“Ø–ª—ç—Ö","–±–∞—Ç–∞–ª–≥–∞–∞–∂—É—É–ª–∞—Ö"]]
EXP_TECH = [
  "–±–∞—Ä –∫–æ–¥ —É–Ω—à—É—É–ª–∞—Ö","QR –∫–æ–¥ —Å–∫–∞–Ω —Ö–∏–π—Ö","—Ñ–∞–π–ª –∏–ª–≥—ç—ç—Ö","—Ñ–∞–π–ª —Ö—É—É–ª–±–∞—Ä–ª–∞—Ö","—Ñ–∞–π–ª —É—Å—Ç–≥–∞—Ö","–ø—Ä–∏–Ω—Ç–µ—Ä –∞—à–∏–≥–ª–∞—Ö",
  "—Ü–∞—Ö–∏–º –±–∞—Ä–∏–º—Ç –∏–ª–≥—ç—ç—Ö","–Ω—É—É—Ü “Ø–≥ —Å—ç—Ä–≥—ç—ç—Ö","–ø–∏–Ω –∫–æ–¥ –æ—Ä—É—É–ª–∞—Ö","–±–∞—Ç–∞–ª–≥–∞–∞–∂—É—É–ª–∞—Ö –∫–æ–¥ –∏–ª–≥—ç—ç—Ö","–∞–ø–ø –Ω—ç—ç—Ö","–∞–ø–ø —Ö–∞–∞—Ö",
  "–≤–µ–± —Ö—É—É–¥–∞—Å “Ø–∑—ç—Ö","–∏–º—ç–π–ª –∏–ª–≥—ç—ç—Ö","–∫–æ–¥ –±–∏—á–∏—Ö","”©–≥”©–≥–¥”©–ª –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö","–º–∞—à–∏–Ω —Å—É—Ä–≥–∞–ª—Ç —Ö–∏–π—Ö","–Ω–µ–π—Ä–æ–Ω —Å“Ø–ª–∂—ç—ç –∞—à–∏–≥–ª–∞—Ö"
]
EXP_DAILY = [
  "–∫–æ—Ñ–µ —É—É—Ö","—Ü–∞–π —É—É—Ö","–¥—ç–ª–≥“Ø“Ø—Ä —è–≤–∞—Ö","—Ä–µ—Å—Ç–æ—Ä–∞–Ω –æ—Ä–æ—Ö","–∫–∞—Ñ–µ —Å—É—É—Ö","–∞—Ö —Ä—É—É –∑–∞–ª–≥–∞—Ö","–≥—ç—Ä—Ç –æ—á–∏—Ö","–∞–∂–∏–ª–¥–∞–∞ —è–≤–∞—Ö",
  "–Ω–æ–º —É–Ω—à–∏—Ö","–∫–∏–Ω–æ “Ø–∑—ç—Ö","–±–æ—Ä–æ–æ –æ—Ä–æ—Ö","—Ü–∞—Å –æ—Ä–æ—Ö","–Ω–∞—Ä –≥–∞—Ä–∞—Ö","—Å–∞–ª—Ö–∏ “Ø–ª—ç—ç—Ö"
]

# Combine & trim to target
expressions = sorted(set(EXP_BANK + EXP_TECH + EXP_DAILY))
# If still short, auto-generate noun+verb pairs
if len(expressions) < TARGET_EXPRESSIONS:
    nouns = BANK + DAILY + TECH
    verbs = [v for v in VERBS if " " not in v] + ["–≥“Ø–π–ª–≥—ç—ç —Ö–∏–π—Ö","–≤–∞–ª—é—Ç —Å–æ–ª–∏—Ö","–∑—ç—ç–ª –∞–≤–∞—Ö","—Ö—É–¥–∞–ª–¥–∞–∂ –∞–≤–∞—Ö"]
    random.shuffle(nouns); random.shuffle(verbs)
    for n, v in itertools.islice(itertools.product(nouns, verbs), TARGET_EXPRESSIONS*2):
        exp = f"{n} {v}"
        expressions.append(exp)
    expressions = sorted(set(expressions))[:TARGET_EXPRESSIONS]

with open(os.path.join(BASE_DIR,"expressions.csv"),"w",encoding="utf-8",newline="") as f:
    w=csv.writer(f); w.writerow(["id","expression"])
    for i,exp in enumerate(expressions,1):
        w.writerow([f"{i:04d}",exp])

# ------------ Build numbers_currency.txt ------------
num_lines = []
base_amounts = list(range(1,21)) + [25,30,40,50,60,70,80,90,100,150,200,300,500,700,900,1000,1500,2000,5000,10000,20000,100000,200000,500000,1000000,2000000,5000000,1000000000]
for amt in base_amounts:
    for cur in CURRENCIES:
        num_lines.append(f"{number_words(amt)} {cur}")
# modified thousand forms for 1..9
for n in range(1,10):
    for cur in CURRENCIES:
        num_lines.append(f"{thousand_modified(n)} {cur}")
numbers_currency = sorted(set(num_lines))
with open(os.path.join(BASE_DIR,"numbers_currency.txt"),"w",encoding="utf-8") as f:
    f.write("\n".join(numbers_currency))

# ------------ Sentence templates ------------
SUBJ = ["–ë–∏","–ê—Ö","–≠–≥—á","–ù–∞–π–∑","“Æ–π–ª—á–ª“Ø“Ø–ª—ç–≥—á","–•—ç—Ä—ç–≥–ª—ç–≥—á","–ú–µ–Ω–µ–∂–µ—Ä","–•“Ø“Ø—Ö—ç–¥","–¢—ç—Ä"]
POSSESSIVE = ["–º–∏–Ω–∏–π","–∞—Ö—ã–Ω","—ç–≥—á–∏–π–Ω","“Ø–π–ª—á–ª“Ø“Ø–ª—ç–≥—á–∏–π–Ω","—Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω"]
PLACES = ["–±–∞–Ω–∫","—Å–∞–ª–±–∞—Ä","–∫–∞—Ñ–µ","–¥—ç–ª–≥“Ø“Ø—Ä","–≥—ç—Ä","—ç–º–Ω—ç–ª—ç–≥","—Å—É—Ä–≥—É—É–ª—å","–∞–∂–∏–ª"]
ACTIONS_BANK = ["–¥–∞–Ω—Å–∞–∞ —à–∞–ª–≥–∞–º–∞–∞—Ä –±–∞–π–Ω–∞","–≥“Ø–π–ª–≥—ç—ç —Ö–∏–π—Å—ç–Ω","—Ç”©–ª–±”©—Ä —Ç”©–ª”©—Ö –≥—ç—Å—ç–Ω —é–º","–≤–∞–ª—é—Ç —Å–æ–ª—å—ë –≥—ç–∂ –±–∞–π–Ω–∞",
                "–∑—ç—ç–ª –∞–≤–∞—Ö —Ö“Ø—Å—ç–ª—Ç ”©–≥—Å”©–Ω","–∫–∞—Ä—Ç –∞—à–∏–≥–ª–∞—Å–∞–Ω","—à–∏–ª–∂“Ø“Ø–ª—ç–≥ –∞–º–∂–∏–ª—Ç—Ç–∞–π –±–æ–ª–ª–æ–æ","—à–∏–ª–∂“Ø“Ø–ª—ç–≥ –∞–º–∂–∏–ª—Ç–≥“Ø–π –±–æ–ª–ª–æ–æ"]
ACTIONS_TECH = ["QR –∫–æ–¥ —É–Ω—à—É—É–ª–∞—Ö –≥—ç–∂ –±–∞–π–Ω–∞","–±–∞—Ä –∫–æ–¥ —É–Ω—à–∏–≥–¥—Å–∞–Ω–≥“Ø–π","—Ñ–∞–π–ª –∏–ª–≥—ç—ç—Å—ç–Ω","—Ñ–∞–π–ª —Ö—É—É–ª–±–∞—Ä–ª–∞—Å–∞–Ω",
                "–Ω—É—É—Ü “Ø–≥—ç—ç —Å—ç—Ä–≥—ç—ç—Ö —Ö—ç—Ä—ç–≥—Ç—ç–π","–∞–ø–ø –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π","–∏–º—ç–π–ª –∏–ª–≥—ç—ç–≥–¥—Å—ç–Ω","–≤–µ–± —Ö—É—É–¥–∞—Å –∞—á–∞–∞–ª—Å–∞–Ω"]
ACTIONS_DAILY = ["–∫–æ—Ñ–µ —É—É–∂ –±–∞–π–Ω–∞","—Ü–∞–π —É—É–∂ —Å—É—É–Ω–∞","–¥—ç–ª–≥“Ø“Ø—Ä –æ—Ä–ª–æ–æ","–±–æ—Ä–æ–æ –æ—Ä–∂ –±–∞–π–Ω–∞","—Å–∞–ª—Ö–∏ —Ö“Ø—á—Ç—ç–π –±–∞–π–Ω–∞","–∫–∏–Ω–æ “Ø–∑—ç–∂ –±–∞–π–Ω–∞","–Ω–æ–º —É–Ω—à–∏–∂ –±–∞–π–Ω–∞"]
TIME_PHRASES = TIME + ["–æ–¥–æ–æ—Ö–æ–Ω","–¥–∞—Ä–∞–∞ –Ω—å","—Å–∞—è—Ö–∞–Ω","—Ç“Ø—Ä“Ø“Ø–Ω","—ç–Ω—ç –¥–æ–ª–æ–æ —Ö–æ–Ω–æ–≥—Ç","–¥–∞—Ä–∞–∞ —Å–∞—Ä–¥"]

def random_amount_sentence():
    amt = random.choice(numbers_currency)
    cur = ""  # already includes currency
    subj = random.choice(SUBJ)
    verb = random.choice(["—à–∏–ª–∂“Ø“Ø–ª–ª—ç—ç","–∞–≤–ª–∞–∞","—Ö–∏–π–≤","–æ—Ä–ª–æ–æ","—Ö–∞—Å–∞–≥–¥–ª–∞–∞","–Ω—ç–º—ç–≥–¥–ª—ç—ç"])
    obj = random.choice(["–¥–∞–Ω—Å–∞–Ω–¥","–¥–∞–Ω—Å–Ω–∞–∞—Å","–±–∞–ª–∞–Ω—Å –¥—ç—ç—Ä","—Ç”©–ª–±”©—Ä—Ç"])
    return f"{subj} {obj} {amt} {verb}."

def random_bank_sentence():
    subj = random.choice(SUBJ)
    t = random.choice(TIME_PHRASES)
    act = random.choice(ACTIONS_BANK)
    return f"{subj} {t} {act}."

def random_tech_sentence():
    subj = random.choice(SUBJ)
    act = random.choice(ACTIONS_TECH)
    return f"{subj} {act}."

def random_daily_sentence():
    subj = random.choice(SUBJ)
    place = random.choice(PLACES)
    act = random.choice(ACTIONS_DAILY)
    t = random.choice(TIME_PHRASES)
    return f"{subj} {place}-–¥ {t} {act}."

def from_expression_sentence(exp):
    # Expand 2‚Äì3 word expression into a clean sentence
    subj = random.choice(SUBJ)
    t = random.choice(["","”©–Ω”©”©–¥”©—Ä","–º–∞—Ä–≥–∞–∞—à","–æ–¥–æ–æ—Ö–æ–Ω","—Å–∞—è—Ö–∞–Ω"])
    t = (t + " ") if t else ""
    # Ensure proper ending
    if exp.endswith("—Ö–∏–π—Ö") or exp.endswith("–∞–≤–∞—Ö") or exp.endswith("—à–∞–ª–≥–∞—Ö") or exp.endswith("–Ω—ç—ç—Ö") or exp.endswith("—Ö–∞–∞—Ö") or exp.endswith("–∏–ª–≥—ç—ç—Ö"):
        ending = random.choice(["–≥—ç—Å—ç–Ω —é–º.","–≥—ç–∂ –±–∞–π–Ω–∞.","–±–æ–ª–Ω–æ.","—Ö–∏–π–ª—ç—ç.","—Ö–∏–π–≤."])
        return f"{subj} {t}{exp} {ending}"
    return f"{subj} {t}{exp}."

# ------------ Generate ~20k sentences (unique, varied) ------------
sent_hash = set()
sentences = []

def push_sentence(s):
    s = " ".join(s.split())  # normalize spaces
    h = hashlib.md5(s.encode("utf-8")).hexdigest()
    if h not in sent_hash:
        sent_hash.add(h)
        sentences.append(s)
        return True
    return False

# Seed from expressions (ensures your ‚Äúone word ‚Üí many sentences‚Äù principle)
for exp in tqdm(expressions, desc="Seeding from expressions"):
    s = from_expression_sentence(exp)
    push_sentence(s)
    if len(sentences) >= TARGET_SENTENCES//4:
        break

# Mix sentence types until we hit TARGET_SENTENCES
generators = [random_bank_sentence, random_tech_sentence, random_daily_sentence, random_amount_sentence]
pbar = tqdm(total=TARGET_SENTENCES, desc="Generating sentences", initial=len(sentences))
while len(sentences) < TARGET_SENTENCES:
    g = random.choice(generators)
    push_sentence(g())
    if random.random() < 0.25 and expressions:
        push_sentence(from_expression_sentence(random.choice(expressions)))
    if random.random() < 0.15:
        # PoV / possessive variation
        poss = random.choice(POSSESSIVE)
        act = random.choice(ACTIONS_BANK + ACTIONS_TECH + ACTIONS_DAILY)
        place = random.choice(PLACES)
        t = random.choice(TIME_PHRASES)
        push_sentence(f"{poss} {place}-–¥ {t} {act}.")
    pbar.n = len(sentences); pbar.refresh()
pbar.close()

# Write sentences.csv
with open(os.path.join(BASE_DIR,"sentences.csv"),"w",encoding="utf-8",newline="") as f:
    w=csv.writer(f); w.writerow(["id","sentence"])
    for i,s in enumerate(sentences,1):
        w.writerow([f"{i:05d}",s])

# Summary print
print("‚úÖ word_list.txt:", len(word_list), "entries")
print("‚úÖ expressions.csv:", len(expressions), "rows")
print("‚úÖ sentences.csv:", len(sentences), "rows (target:", TARGET_SENTENCES, ")")
print("‚úÖ numbers_currency.txt:", len(numbers_currency), "rows")
print("üìÇ Saved in:", BASE_DIR)
